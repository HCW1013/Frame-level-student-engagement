{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Xbmovnn842WdkFmFIYfOpipn5wci49sP#scrollTo=C93b1yUGCMw5)"
      ],
      "metadata": {
        "id": "C93b1yUGCMw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Documents/GitHub/Frame-level-student-engagement"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq9Kdql0Gqqw",
        "outputId": "c0181a5c-ebd2-4854-dc07-a243f0fcf180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C:\\Users\\rijju\\Documents\\GitHub\\Frame-level-student-engagement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from DataFormatter import DataFormatter\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from Tab_CNN import CNNModel"
      ],
      "metadata": {
        "id": "cWHZ8iXcCwVx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvsQSDYTIQTr",
        "outputId": "3bf6c1c0-21d0-49c5-8e0a-85bdce66e775"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/c/Users/rijju/Documents/GitHub/Frame-level-student-engagement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#replace the path according to the path to the dataset\n",
        "df = pd.read_csv(\"Data/WACV_train_data.csv\")\n",
        "df= df.loc[:,\"gaze_0_x\":]\n",
        "train_split, val_split = 0.7, 0.15\n",
        "\n",
        "formatter = DataFormatter(train_split, val_split)\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = formatter.dataframeFormat(df)\n",
        "# Instantiate the CNNModel class\n",
        "num_classes = 3\n",
        "inp_shape = x_train.shape[1:]\n",
        "cnn_model = CNNModel(num_classes,inp_shape)\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "history = cnn_model.train(x_train, y_train, batch_size, epochs)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = cnn_model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy:\", accuracy)\n",
        "\n",
        "model= cnn_model.model\n",
        "# make a reference to model's input layer\n",
        "inp = model.input\n",
        "\n",
        "# make a new softmax layer with num_classes neurons\n",
        "new_classification_layer = Dense(4, activation='softmax')\n",
        "\n",
        "# connect our new layer to the second to last layer in model, and make a reference to it\n",
        "out = new_classification_layer(model.layers[-2].output)\n",
        "\n",
        "# create a new network between inp and out\n",
        "model_new = Model(inp, out)\n",
        "\n",
        "# make all layers untrainable by freezing weights (except for last layer)\n",
        "for l, layer in enumerate(model_new.layers[:-1]):\n",
        "    layer.trainable = False\n",
        "\n",
        "# ensure the last layer is trainable/not frozen\n",
        "for l, layer in enumerate(model_new.layers[-1:]):\n",
        "    layer.trainable = True\n",
        "\n",
        "model_new.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "dfD = pd.read_csv(\"Data/DAiSEE_TL_data.csv\")\n",
        "dfD= dfD.loc[:,\"gaze_0_x\":]\n",
        "xD_train, xD_val, xD_test, yD_train, yD_val, yD_test = formatter.dataframeFormat(dfD)\n",
        "\n",
        "history2 = model_new.fit(xD_train, yD_train, \n",
        "                         batch_size=batch_size, \n",
        "                         epochs=epochs, \n",
        "                         validation_data=(xD_val, yD_val))\n",
        "\n",
        "#comparing both model's loss and accuracy\n",
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history.history[\"loss\"], label=\"WACV val loss\")\n",
        "ax.plot(history2.history[\"loss\"], label=\"DAiSEE val loss\")\n",
        "# ax.set_title(\"validation loss\")\n",
        "ax.legend(loc=\"upper left\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "ax.set_ylabel(\"validation loss\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"accuracy\"], label=\"WACV val accuracy\")\n",
        "ax2.plot(history2.history[\"accuracy\"],label=\"DAiSEE val accuracy\")\n",
        "# ax2.set_title(\"validation accuracy\")\n",
        "ax2.legend(loc=\"lower right\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylabel(\"validation accuracy\")\n",
        "ax2.set_ylim(0, 1)\n",
        "plt.savefig(\"Results/TF_los_acc_OF.pdf\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZcFbhkirCESW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yD_pred = model_new.predict(xD_test)\n",
        "\n",
        "# Reshape predicted and true labels into binary vectors\n",
        "y_pred_binary = np.argmax(yD_pred, axis=1)\n",
        "y_true_binary = np.argmax(yD_test, axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "Ns7ZPbLiGF8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "\n",
        "# serialize model to YAML\n",
        "model_yaml = model_new.to_json()\n",
        "with open(\"Model/model_OF.yaml\", \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "# serialize weights to HDF5\n",
        "model_new.save_weights(\"Model/model_OF.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "id": "5y83cAgHC1kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the model\n",
        "from tensorflow.keras.models import Sequential, model_from_json\n",
        "yaml_file = open('Model_OF.yaml', 'r')\n",
        "loaded_model_yaml = yaml_file.read()\n",
        "yaml_file.close()\n",
        "loaded_model = model_from_json(loaded_model_yaml)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"Model/model_OF.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "metadata": {
        "id": "Bbya5LT1C98V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}